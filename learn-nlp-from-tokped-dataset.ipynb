{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e64ba9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-25T01:01:50.079321Z",
     "iopub.status.busy": "2025-12-25T01:01:50.078892Z",
     "iopub.status.idle": "2025-12-25T01:01:57.845696Z",
     "shell.execute_reply": "2025-12-25T01:01:57.844442Z"
    },
    "papermill": {
     "duration": 7.775316,
     "end_time": "2025-12-25T01:01:57.847931",
     "exception": false,
     "start_time": "2025-12-25T01:01:50.072615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysastrawi\r\n",
      "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl.metadata (892 bytes)\r\n",
      "Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pysastrawi\r\n",
      "Successfully installed pysastrawi-1.2.0\r\n",
      "/kaggle/input/tokopedia-product-and-review-dataset/tokopedia_products_with_review.json\n",
      "/kaggle/input/tokopedia-product-and-review-dataset/tokopedia_products_with_review.csv\n",
      "/kaggle/input/stopwords/stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "!pip install pysastrawi\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b704628c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:01:57.858071Z",
     "iopub.status.busy": "2025-12-25T01:01:57.856713Z",
     "iopub.status.idle": "2025-12-25T01:02:14.384791Z",
     "shell.execute_reply": "2025-12-25T01:02:14.383623Z"
    },
    "papermill": {
     "duration": 16.535472,
     "end_time": "2025-12-25T01:02:14.387099",
     "exception": false,
     "start_time": "2025-12-25T01:01:57.851627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/kaggle/input/tokopedia-product-and-review-dataset/tokopedia_products_with_review.csv')\n",
    "df = pd.read_json('/kaggle/input/tokopedia-product-and-review-dataset/tokopedia_products_with_review.json')\n",
    "dataset_list = df.head(50).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666fde87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:14.396038Z",
     "iopub.status.busy": "2025-12-25T01:02:14.395718Z",
     "iopub.status.idle": "2025-12-25T01:02:14.565018Z",
     "shell.execute_reply": "2025-12-25T01:02:14.564024Z"
    },
    "papermill": {
     "duration": 0.17662,
     "end_time": "2025-12-25T01:02:14.567276",
     "exception": false,
     "start_time": "2025-12-25T01:02:14.390656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "filename = '/kaggle/input/stopwords/stopwords.txt'\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Open the file in read mode ('r') using a context manager\n",
    "with open(filename, 'r') as file:\n",
    "    # Iterate over each line in the file\n",
    "    for line in file:\n",
    "        # Optional: Use rstrip() to remove trailing whitespace/newlines\n",
    "        processed_line = line.strip()\n",
    "        text = stemmer.stem(processed_line)\n",
    "        \n",
    "        # Process the line (e.g., print it)\n",
    "        if(processed_line and text not in stopwords):\n",
    "            stopwords.append(text)\n",
    "\n",
    "len(dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca8976d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:14.576225Z",
     "iopub.status.busy": "2025-12-25T01:02:14.575851Z",
     "iopub.status.idle": "2025-12-25T01:02:15.278046Z",
     "shell.execute_reply": "2025-12-25T01:02:15.277053Z"
    },
    "papermill": {
     "duration": 0.709631,
     "end_time": "2025-12-25T01:02:15.280298",
     "exception": false,
     "start_time": "2025-12-25T01:02:14.570667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9271, 3)\n"
     ]
    }
   ],
   "source": [
    "type(dataset_list)\n",
    "reviews = list(map(lambda review: review['reviews'], dataset_list))\n",
    "reviews = [item for sublist in reviews for item in sublist]\n",
    "reviews = list(map(lambda review: {\n",
    "    'message': review['message'],\n",
    "    'rating': review['review_rating'],\n",
    "    'sentiment': 'positive' if review['review_rating'] > 3 else 'negative'\n",
    "}, reviews))\n",
    "df = pd.DataFrame(reviews)\n",
    "print(df.shape)\n",
    "# for review in reviews:\n",
    "#     print(review['rating'], review['sentiment'], review['message'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a0ebdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:15.289873Z",
     "iopub.status.busy": "2025-12-25T01:02:15.289529Z",
     "iopub.status.idle": "2025-12-25T01:02:16.701012Z",
     "shell.execute_reply": "2025-12-25T01:02:16.700051Z"
    },
    "papermill": {
     "duration": 1.418798,
     "end_time": "2025-12-25T01:02:16.703097",
     "exception": false,
     "start_time": "2025-12-25T01:02:15.284299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    1044\n",
       "negative     727\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopword(sentence): \n",
    "    arr = sentence.split()\n",
    "    resArr = []\n",
    "    for text in arr:\n",
    "        if(text not in stopwords):\n",
    "            resArr.append(text)\n",
    "    return ' '.join(resArr)\n",
    "\n",
    "\n",
    "def handle_negation_enhanced(text):\n",
    "    \"\"\"Enhanced negation handling\"\"\"\n",
    "    \n",
    "    # More comprehensive negation list\n",
    "    negations = [\n",
    "        'tidak', 'tak', 'bukan', 'jangan', 'belum', 'tanpa',\n",
    "        'gak', 'ga', 'engga', 'nggak', 'kagak', 'ngg', 'ngga',  # ← Slang variations!\n",
    "        'gk', 'g', 'tdk'  # Abbreviations\n",
    "    ]\n",
    "    \n",
    "    for neg in negations:\n",
    "        # More flexible pattern (handle spacing issues)\n",
    "        pattern = r'\\b' + neg + r'\\s+(\\w+)'\n",
    "        text = re.sub(pattern, r'not \\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocessing steps:\n",
    "    1. Lowercase\n",
    "    2. Remove special characters\n",
    "    3. Remove stopwords\n",
    "    4. Stemming\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "    text = stemmer.stem(text)\n",
    "\n",
    "    return handle_negation_enhanced(text)\n",
    "\n",
    "\n",
    "clean_message = []\n",
    "for review in reviews:\n",
    "    # clean_message.append(remove_stopword(preprocess_text(review['message'])))\n",
    "    clean_message.append((preprocess_text(review['message'])))\n",
    "df['clean_message'] = pd.Series(clean_message)\n",
    "df = df[['message', 'clean_message', 'rating', 'sentiment']]\n",
    "\n",
    "indices_to_drop = df[df['sentiment'] == 'positive'].index[:7500]\n",
    "\n",
    "# 3. Hapus baris berdasarkan indeks tersebut\n",
    "df = df.drop(indices_to_drop)\n",
    "\n",
    "\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c62a392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:16.712247Z",
     "iopub.status.busy": "2025-12-25T01:02:16.711829Z",
     "iopub.status.idle": "2025-12-25T01:02:16.721444Z",
     "shell.execute_reply": "2025-12-25T01:02:16.720034Z"
    },
    "papermill": {
     "duration": 0.016916,
     "end_time": "2025-12-25T01:02:16.723656",
     "exception": false,
     "start_time": "2025-12-25T01:02:16.706740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  positive: 1044 (58.9%)\n",
      "  negative: 727 (41.1%)\n"
     ]
    }
   ],
   "source": [
    "# Features and target\n",
    "X = df['clean_message']  # ← Use cleaned text!\n",
    "y = df['sentiment']\n",
    "\n",
    "class_counts = y.value_counts()\n",
    "for sentiment, count in class_counts.items():\n",
    "    percentage = (count / len(y)) * 100\n",
    "    print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "if class_counts.min() / class_counts.max() < 0.5:\n",
    "    print(\"\\n⚠️  WARNING: Data is imbalanced!\")\n",
    "    print(\"  Consider using class_weight='balanced' in models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b6823d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:16.732983Z",
     "iopub.status.busy": "2025-12-25T01:02:16.732614Z",
     "iopub.status.idle": "2025-12-25T01:02:19.144259Z",
     "shell.execute_reply": "2025-12-25T01:02:19.143169Z"
    },
    "papermill": {
     "duration": 2.419338,
     "end_time": "2025-12-25T01:02:19.146648",
     "exception": false,
     "start_time": "2025-12-25T01:02:16.727310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_message</th>\n",
       "      <th>aamiin</th>\n",
       "      <th>abang</th>\n",
       "      <th>abang kurir</th>\n",
       "      <th>abg</th>\n",
       "      <th>abg kurir</th>\n",
       "      <th>abis</th>\n",
       "      <th>abis sikat</th>\n",
       "      <th>abis siram</th>\n",
       "      <th>abs</th>\n",
       "      <th>...</th>\n",
       "      <th>yg udah</th>\n",
       "      <th>yg umumny</th>\n",
       "      <th>yg untuk</th>\n",
       "      <th>yg varian</th>\n",
       "      <th>yingkatkan</th>\n",
       "      <th>yingkatkan lagi</th>\n",
       "      <th>you</th>\n",
       "      <th>you can</th>\n",
       "      <th>you seller</th>\n",
       "      <th>zonk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc_0</th>\n",
       "      <td>ini dua kali nya akhir saya beli krn yg pertam...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_1</th>\n",
       "      <td>besi untuk pasang ke dinding not di amplas dan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_2</th>\n",
       "      <td>sayang sekali ada pecah sekitar cm not tau dar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_3</th>\n",
       "      <td>ada yg bentur cacat tapi gpp sdikit lah</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_4</th>\n",
       "      <td>kecewa sih pertama karena lama bngt paket dua ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_5</th>\n",
       "      <td>buruk salah kirim warna jawab suka padahal di ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_6</th>\n",
       "      <td>barang cukup bagus hanya saja kerangka ambal k...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_7</th>\n",
       "      <td>terima barang ada penyok dikit di ujung lain k...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_8</th>\n",
       "      <td>warna not sesuai</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_9</th>\n",
       "      <td>lumayan bagus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 13108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_message  aamiin  abang  \\\n",
       "Doc_0  ini dua kali nya akhir saya beli krn yg pertam...     0.0    0.0   \n",
       "Doc_1  besi untuk pasang ke dinding not di amplas dan...     0.0    0.0   \n",
       "Doc_2  sayang sekali ada pecah sekitar cm not tau dar...     0.0    0.0   \n",
       "Doc_3            ada yg bentur cacat tapi gpp sdikit lah     0.0    0.0   \n",
       "Doc_4  kecewa sih pertama karena lama bngt paket dua ...     0.0    0.0   \n",
       "Doc_5  buruk salah kirim warna jawab suka padahal di ...     0.0    0.0   \n",
       "Doc_6  barang cukup bagus hanya saja kerangka ambal k...     0.0    0.0   \n",
       "Doc_7  terima barang ada penyok dikit di ujung lain k...     0.0    0.0   \n",
       "Doc_8                                   warna not sesuai     0.0    0.0   \n",
       "Doc_9                                      lumayan bagus     0.0    0.0   \n",
       "\n",
       "       abang kurir  abg  abg kurir  abis  abis sikat  abis siram  abs  ...  \\\n",
       "Doc_0          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_1          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_2          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_3          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_4          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_5          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_6          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_7          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_8          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "Doc_9          0.0  0.0        0.0   0.0         0.0         0.0  0.0  ...   \n",
       "\n",
       "       yg udah  yg umumny  yg untuk  yg varian  yingkatkan  yingkatkan lagi  \\\n",
       "Doc_0      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_1      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_2      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_3      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_4      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_5      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_6      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_7      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_8      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "Doc_9      0.0        0.0       0.0        0.0         0.0              0.0   \n",
       "\n",
       "       you  you can  you seller  zonk  \n",
       "Doc_0  0.0      0.0         0.0   0.0  \n",
       "Doc_1  0.0      0.0         0.0   0.0  \n",
       "Doc_2  0.0      0.0         0.0   0.0  \n",
       "Doc_3  0.0      0.0         0.0   0.0  \n",
       "Doc_4  0.0      0.0         0.0   0.0  \n",
       "Doc_5  0.0      0.0         0.0   0.0  \n",
       "Doc_6  0.0      0.0         0.0   0.0  \n",
       "Doc_7  0.0      0.0         0.0   0.0  \n",
       "Doc_8  0.0      0.0         0.0   0.0  \n",
       "Doc_9  0.0      0.0         0.0   0.0  \n",
       "\n",
       "[10 rows x 13108 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['clean_message'])\n",
    "X\n",
    "\n",
    "\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df_tfidf = pd.DataFrame(\n",
    "    X[:10].toarray(),  # First 5 docs\n",
    "    columns=feature_names,\n",
    "    index=[f\"Doc_{i}\" for i in range(10)]\n",
    ")\n",
    "\n",
    "df_tfidf.insert(0, 'clean_message', df['clean_message'][:10].values)\n",
    "df_tfidf\n",
    "# df_tfidf.to_csv('/tf-idf-word-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c20468b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:19.157126Z",
     "iopub.status.busy": "2025-12-25T01:02:19.156520Z",
     "iopub.status.idle": "2025-12-25T01:02:19.163149Z",
     "shell.execute_reply": "2025-12-25T01:02:19.162216Z"
    },
    "papermill": {
     "duration": 0.014711,
     "end_time": "2025-12-25T01:02:19.165435",
     "exception": false,
     "start_time": "2025-12-25T01:02:19.150724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 31163 stored elements and shape (1771, 13107)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87c565f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:19.175555Z",
     "iopub.status.busy": "2025-12-25T01:02:19.175211Z",
     "iopub.status.idle": "2025-12-25T01:02:25.694307Z",
     "shell.execute_reply": "2025-12-25T01:02:25.693151Z"
    },
    "papermill": {
     "duration": 6.5277,
     "end_time": "2025-12-25T01:02:25.697318",
     "exception": false,
     "start_time": "2025-12-25T01:02:19.169618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model svc\n",
      "train_accuracy is 96.61\n",
      "test_accuracy is 86.2\n",
      "======================================================================\n",
      "model naive_bayes\n",
      "train_accuracy is 91.1\n",
      "test_accuracy is 85.35\n",
      "======================================================================\n",
      "model logistic_regression\n",
      "train_accuracy is 91.53\n",
      "test_accuracy is 86.48\n",
      "======================================================================\n",
      "model random_forest\n",
      "train_accuracy is 97.1\n",
      "test_accuracy is 86.2\n",
      "======================================================================\n",
      "SVC:  Bangsat jancuk, ga guna barangnya => negative ✅\n",
      "Naive Bayes:  Bangsat jancuk, ga guna barangnya => positive ❌\n",
      "Logistic Regression:  Bangsat jancuk, ga guna barangnya => negative ✅\n",
      "Random Forest:  Bangsat jancuk, ga guna barangnya => negative ✅\n",
      "======================================================================\n",
      "SVC:  Sangat berguna => positive ✅\n",
      "Naive Bayes:  Sangat berguna => positive ✅\n",
      "Logistic Regression:  Sangat berguna => positive ✅\n",
      "Random Forest:  Sangat berguna => positive ✅\n",
      "======================================================================\n",
      "SVC:  Barang tidak berguna sama sekali => negative ✅\n",
      "Naive Bayes:  Barang tidak berguna sama sekali => negative ✅\n",
      "Logistic Regression:  Barang tidak berguna sama sekali => negative ✅\n",
      "Random Forest:  Barang tidak berguna sama sekali => negative ✅\n",
      "======================================================================\n",
      "SVC:  Terlalu mahal kualitas jelek => negative ✅\n",
      "Naive Bayes:  Terlalu mahal kualitas jelek => negative ✅\n",
      "Logistic Regression:  Terlalu mahal kualitas jelek => negative ✅\n",
      "Random Forest:  Terlalu mahal kualitas jelek => negative ✅\n",
      "======================================================================\n",
      "SVC:  produk bagus => positive ✅\n",
      "Naive Bayes:  produk bagus => positive ✅\n",
      "Logistic Regression:  produk bagus => positive ✅\n",
      "Random Forest:  produk bagus => positive ✅\n",
      "======================================================================\n",
      "SVC:  produk tidak bagus => negative ✅\n",
      "Naive Bayes:  produk tidak bagus => positive ❌\n",
      "Logistic Regression:  produk tidak bagus => negative ✅\n",
      "Random Forest:  produk tidak bagus => negative ✅\n",
      "======================================================================\n",
      "SVC:  sangat bagus => positive ✅\n",
      "Naive Bayes:  sangat bagus => positive ✅\n",
      "Logistic Regression:  sangat bagus => positive ✅\n",
      "Random Forest:  sangat bagus => positive ✅\n",
      "======================================================================\n",
      "SVC:  tidak bagus sama sekali => negative ✅\n",
      "Naive Bayes:  tidak bagus sama sekali => negative ✅\n",
      "Logistic Regression:  tidak bagus sama sekali => negative ✅\n",
      "Random Forest:  tidak bagus sama sekali => negative ✅\n",
      "======================================================================\n",
      "SVC:  produk tolol, seller tidak ramah => negative ✅\n",
      "Naive Bayes:  produk tolol, seller tidak ramah => positive ❌\n",
      "Logistic Regression:  produk tolol, seller tidak ramah => negative ✅\n",
      "Random Forest:  produk tolol, seller tidak ramah => positive ❌\n",
      "======================================================================\n",
      "SVC:  aku suka belanja disini, barang lengkap dan seller responsif => positive ✅\n",
      "Naive Bayes:  aku suka belanja disini, barang lengkap dan seller responsif => positive ✅\n",
      "Logistic Regression:  aku suka belanja disini, barang lengkap dan seller responsif => positive ✅\n",
      "Random Forest:  aku suka belanja disini, barang lengkap dan seller responsif => positive ✅\n",
      "======================================================================\n",
      "SVC:  aku suka produk ini, sangat membantu dan berguna untuk sehari-hari => positive ✅\n",
      "Naive Bayes:  aku suka produk ini, sangat membantu dan berguna untuk sehari-hari => positive ✅\n",
      "Logistic Regression:  aku suka produk ini, sangat membantu dan berguna untuk sehari-hari => positive ✅\n",
      "Random Forest:  aku suka produk ini, sangat membantu dan berguna untuk sehari-hari => positive ✅\n",
      "======================================================================\n",
      "SVC:  hari yg indah, membuat hati ingin liburan dan membeli produk yang sangat bagus ini, terimakasih tokped => positive ✅\n",
      "Naive Bayes:  hari yg indah, membuat hati ingin liburan dan membeli produk yang sangat bagus ini, terimakasih tokped => positive ✅\n",
      "Logistic Regression:  hari yg indah, membuat hati ingin liburan dan membeli produk yang sangat bagus ini, terimakasih tokped => positive ✅\n",
      "Random Forest:  hari yg indah, membuat hati ingin liburan dan membeli produk yang sangat bagus ini, terimakasih tokped => positive ✅\n",
      "======================================================================\n",
      "accuracy for svc is 100.0\n",
      "accuracy for naive_bayes is 75.0\n",
      "accuracy for logistic_regression is 100.0\n",
      "accuracy for random_forest is 91.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def process_and_convert_text(text):\n",
    "    text = (preprocess_text(text))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2,random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "models = {\n",
    "    'svc' : SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'naive_bayes': MultinomialNB(),\n",
    "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "train_indices = y_train.index\n",
    "test_indices = y_test.index\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"model {name}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "     # TRAIN SET COMPARISON\n",
    "    df_train_comparison = pd.DataFrame({\n",
    "        'message': df['message'].loc[train_indices].values,\n",
    "        'sentiment_original': y_train.values,\n",
    "        'sentiment_pred': y_train_pred\n",
    "    })\n",
    "    train_accuracy = round(accuracy_score(y_train, y_train_pred) * 100, 2)\n",
    "    test_accuracy = round(accuracy_score(y_test, y_test_pred) * 100, 2)\n",
    "    print(f\"train_accuracy is {train_accuracy}\\ntest_accuracy is {test_accuracy}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "text_test = [\n",
    "    {\n",
    "        'message': 'Bangsat jancuk, ga guna barangnya',\n",
    "        'expect': 'negative'\n",
    "    },\n",
    "    {\n",
    "        'message': 'Sangat berguna',\n",
    "        'expect': 'positive'\n",
    "    },\n",
    "    {\n",
    "        'message': 'Barang tidak berguna sama sekali',\n",
    "        'expect': 'negative'\n",
    "    },\n",
    "    {\n",
    "        'message': 'Terlalu mahal kualitas jelek',\n",
    "        'expect': 'negative',\n",
    "    },\n",
    "    {\n",
    "        'message': 'produk bagus',\n",
    "        'expect': 'positive'\n",
    "    }, \n",
    "    {\n",
    "        'message': 'produk tidak bagus',\n",
    "        'expect': 'negative'\n",
    "    },\n",
    "    {\n",
    "        'message': 'sangat bagus',\n",
    "        'expect': 'positive'\n",
    "    },\n",
    "    {\n",
    "        'message': 'tidak bagus sama sekali',\n",
    "        'expect': 'negative'\n",
    "    },\n",
    "    {\n",
    "        'message': 'produk tolol, seller tidak ramah',\n",
    "        'expect': 'negative'\n",
    "    },\n",
    "    {\n",
    "        'message': 'aku suka belanja disini, barang lengkap dan seller responsif',\n",
    "        'expect': 'positive'\n",
    "    },\n",
    "    {\n",
    "        'message': 'aku suka produk ini, sangat membantu dan berguna untuk sehari-hari',\n",
    "        'expect': 'positive'\n",
    "    },\n",
    "    {\n",
    "        'message': 'hari yg indah, membuat hati ingin liburan dan membeli produk yang sangat bagus ini, terimakasih tokped',\n",
    "        'expect': 'positive'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "num_correct_model = {\n",
    "    'svc': 0,\n",
    "    'naive_bayes': 0,\n",
    "    'logistic_regression': 0,\n",
    "    'random_forest': 0\n",
    "}\n",
    "\n",
    "for test in text_test:\n",
    "    v = vectorizer.transform([(preprocess_text(test['message']))]) \n",
    "    expect = test['expect']\n",
    "    svc_predict = models['svc'].predict(v)[0]\n",
    "    naive_bayes_predict = models['naive_bayes'].predict(v)[0]\n",
    "    logistic_regression_predict = models['logistic_regression'].predict(v)[0]\n",
    "    random_forest_predict = models['random_forest'].predict(v)[0]\n",
    "\n",
    "    svc_correct = expect == svc_predict\n",
    "    naive_bayes_correct = expect == naive_bayes_predict\n",
    "    logistic_regression_correct = expect == logistic_regression_predict\n",
    "    random_forest_correct = expect == random_forest_predict\n",
    "\n",
    "    if(svc_correct): \n",
    "        num_correct_model['svc'] = num_correct_model['svc'] + 1 \n",
    "    if(naive_bayes_correct):\n",
    "        num_correct_model['naive_bayes'] = num_correct_model['naive_bayes'] + 1  \n",
    "    if(logistic_regression_correct):\n",
    "        num_correct_model['logistic_regression'] = num_correct_model['logistic_regression'] + 1 \n",
    "    if(random_forest_correct):\n",
    "        num_correct_model['random_forest'] = num_correct_model['random_forest'] + 1  \n",
    "    \n",
    "    print('SVC: ', test['message'], '=>' , svc_predict,  '✅' if svc_correct else '❌')\n",
    "    print('Naive Bayes: ',test['message'], '=>', naive_bayes_predict, '✅' if naive_bayes_correct else '❌')\n",
    "    print('Logistic Regression: ',test['message'], '=>', logistic_regression_predict, '✅' if logistic_regression_correct else '❌')\n",
    "    print('Random Forest: ', test['message'], '=>', random_forest_predict, '✅' if random_forest_correct else '❌')\n",
    "    print('='*70)\n",
    "\n",
    "for model, num_correct in num_correct_model.items():\n",
    "    print(f\"accuracy for {model} is {round(num_correct / len(text_test) * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ca1a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:25.708154Z",
     "iopub.status.busy": "2025-12-25T01:02:25.707660Z",
     "iopub.status.idle": "2025-12-25T01:02:25.717515Z",
     "shell.execute_reply": "2025-12-25T01:02:25.716478Z"
    },
    "papermill": {
     "duration": 0.017984,
     "end_time": "2025-12-25T01:02:25.719762",
     "exception": false,
     "start_time": "2025-12-25T01:02:25.701778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bangsat jancuk not guna barang'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_pct = df['sentiment'].value_counts(normalize=True) * 100\n",
    "class_pct.max() / class_pct.min()\n",
    "preprocess_text('bangsat jancuk ga guna barang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d12734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:25.733093Z",
     "iopub.status.busy": "2025-12-25T01:02:25.732698Z",
     "iopub.status.idle": "2025-12-25T01:02:40.819773Z",
     "shell.execute_reply": "2025-12-25T01:02:40.818633Z"
    },
    "papermill": {
     "duration": 15.096428,
     "end_time": "2025-12-25T01:02:40.821944",
     "exception": false,
     "start_time": "2025-12-25T01:02:25.725516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CROSS-VALIDATION (5-FOLD)\n",
      "======================================================================\n",
      "model svc\n",
      "metric accuracy\n",
      "train_mean : 96.68\n",
      "train_std : 0.25\n",
      "test_mean : 85.32\n",
      "test_std : 2.09\n",
      "======================================================================\n",
      "model naive_bayes\n",
      "metric accuracy\n",
      "train_mean : 91.38\n",
      "train_std : 0.65\n",
      "test_mean : 79.33\n",
      "test_std : 2.05\n",
      "======================================================================\n",
      "model logistic_regression\n",
      "metric accuracy\n",
      "train_mean : 91.73\n",
      "train_std : 0.63\n",
      "test_mean : 81.88\n",
      "test_std : 3.35\n",
      "======================================================================\n",
      "model random_forest\n",
      "metric accuracy\n",
      "train_mean : 97.11\n",
      "train_std : 0.36\n",
      "test_mean : 82.89\n",
      "test_std : 2.1\n",
      "======================================================================\n",
      "best model is svc with 85.32 +- 2.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CROSS-VALIDATION (5-FOLD)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, pos_label='positive', average='binary'),\n",
    "    'recall': make_scorer(recall_score, pos_label='positive', average='binary'),\n",
    "    'f1': make_scorer(f1_score, pos_label='positive', average='binary')\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'svc' : SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'naive_bayes': MultinomialNB(),\n",
    "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "\n",
    "dict_accuracy_model = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"model {name}\")\n",
    "\n",
    "     # Perform cross-validation\n",
    "    cv_scores = cross_validate(\n",
    "        model, \n",
    "        X,  # Full dataset\n",
    "        y,\n",
    "        cv=5,  # 5-fold\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1  # Use all CPU cores\n",
    "    )\n",
    "\n",
    "    # Calculate statistics\n",
    "    for metric in ['accuracy']:\n",
    "        train_key = f'train_{metric}'\n",
    "        test_key = f'test_{metric}'\n",
    "        \n",
    "        train_mean = cv_scores[train_key].mean()\n",
    "        train_std = cv_scores[train_key].std()\n",
    "        test_mean = cv_scores[test_key].mean()\n",
    "        test_std = cv_scores[test_key].std()\n",
    "\n",
    "        rounded_test_mean = round(test_mean * 100, 2)\n",
    "        rounded_test_std = round(test_std * 100, 2)\n",
    "        dict_accuracy_model[name] = (rounded_test_mean, rounded_test_std)\n",
    "        \n",
    "        print(f\"metric {metric}\")\n",
    "        print(f\"train_mean : {round(train_mean * 100, 2)}\")\n",
    "        print(f\"train_std : {round(train_std * 100, 2)}\")\n",
    "        print(f\"test_mean : {round(test_mean * 100 , 2)}\")\n",
    "        print(f\"test_std : {round(test_std * 100, 2)}\")\n",
    "        \n",
    "    print('='*70)\n",
    "    \n",
    "max_model = max(dict_accuracy_model.items(), key=lambda item: item[1][0])\n",
    "best_model_name = max_model[0]\n",
    "print(f\"best model is {best_model_name} with {max_model[1][0]} +- {max_model[1][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f40c887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T01:02:40.833509Z",
     "iopub.status.busy": "2025-12-25T01:02:40.833149Z",
     "iopub.status.idle": "2025-12-25T01:02:42.871547Z",
     "shell.execute_reply": "2025-12-25T01:02:42.869985Z"
    },
    "papermill": {
     "duration": 2.04705,
     "end_time": "2025-12-25T01:02:42.873822",
     "exception": false,
     "start_time": "2025-12-25T01:02:40.826772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy is 96.61208356860531\n",
      "======================================================================\n",
      "model svc Bangsat jancuk, ga guna barangnya => negative ✅\n",
      "======================================================================\n",
      "model svc Sangat berguna => positive ✅\n",
      "======================================================================\n",
      "model svc Barang tidak berguna sama sekali => negative ✅\n",
      "======================================================================\n",
      "model svc Terlalu mahal kualitas jelek => negative ✅\n",
      "======================================================================\n",
      "model svc produk bagus => positive ✅\n",
      "======================================================================\n",
      "model svc produk tidak bagus => negative ✅\n",
      "======================================================================\n",
      "model svc sangat bagus => positive ✅\n",
      "======================================================================\n",
      "model svc tidak bagus sama sekali => negative ✅\n",
      "======================================================================\n",
      "model svc produk tolol, seller tidak ramah => negative ✅\n",
      "======================================================================\n",
      "model svc aku suka belanja disini, barang lengkap dan seller responsif => positive ✅\n",
      "======================================================================\n",
      "model svc aku suka produk ini, sangat membantu dan berguna untuk sehari-hari => positive ✅\n",
      "======================================================================\n",
      "model svc hari yg indah, membuat hati ingin liburan dan membeli produk yang sangat bagus ini, terimakasih tokped => positive ✅\n",
      "======================================================================\n",
      "accuracy for svc using test case is 100.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_for_testing = {\n",
    "    'svc' : SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'naive_bayes': MultinomialNB(),\n",
    "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_final = models_for_testing[best_model_name]\n",
    "model_final.fit(X, y)\n",
    "y_pred = model_final.predict(X)\n",
    "\n",
    "count_correct = 0\n",
    "for index, x in enumerate(y_pred):\n",
    "    if x == list(y)[index]:\n",
    "        count_correct+=1\n",
    "    \n",
    "print(f\"train accuracy is {count_correct/len(y) * 100}\")\n",
    "\n",
    "print('='*70)\n",
    "\n",
    "num_correct_test = 0\n",
    "for test in text_test:\n",
    "    v = vectorizer.transform([(preprocess_text(test['message']))]) \n",
    "    expect = test['expect']\n",
    "    final_model_predict = model_final.predict(v)[0]\n",
    "    \n",
    "\n",
    "    final_model_correct = expect == final_model_predict\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(final_model_correct): \n",
    "        num_correct_test = num_correct_test + 1 \n",
    "    \n",
    "    \n",
    "    print(f'model {best_model_name}', test['message'], '=>' , final_model_predict,  '✅' if final_model_correct else '❌')\n",
    "    \n",
    "    print('='*70)\n",
    "\n",
    "print(f\"accuracy for {best_model_name} using test case is {round(num_correct_test / len(text_test) * 100 ,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03111876",
   "metadata": {
    "papermill": {
     "duration": 0.004674,
     "end_time": "2025-12-25T01:02:42.883310",
     "exception": false,
     "start_time": "2025-12-25T01:02:42.878636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b7c9d",
   "metadata": {
    "papermill": {
     "duration": 0.004556,
     "end_time": "2025-12-25T01:02:42.892517",
     "exception": false,
     "start_time": "2025-12-25T01:02:42.887961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3699350,
     "sourceId": 6414172,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8863392,
     "sourceId": 13911435,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.903806,
   "end_time": "2025-12-25T01:02:45.523385",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T01:01:45.619579",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
